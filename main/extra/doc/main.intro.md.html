<!DOCTYPE html>
<html>
  <head>
  <meta charset='UTF-8'>
  <title>Kermit(main)</title>
  <script src='../../javascript/application.js'></script>
  <script src='../../javascript/search.js'></script>
  <link rel='stylesheet' href='../../stylesheets/application.css' type='text/css'>
</head>
  <body>
    <div id='base' data-path='../../'></div>
<div id='header'>
  <div id='menu'>
    <a href='../../extra/doc/main.intro.md.html' title='Kermit(main)'>
      Kermit(main)
    </a>
    &raquo;
    <a href='../../alphabetical_index.html' title='Index'>
      Index
    </a>
    &raquo;
    <span class='title'>doc</span>
    &raquo;
    <span class='title'>main.intro.md</span>
  </div>
</div>
    <div id='content'>
      <nav class='toc'>
        <p class='title'>
          <a class='hide_toc' href='#'>
            <strong>Table of Contents</strong>
          </a>
          <small>
            (<a class='float_toc' href='#'>left</a>)
          </small>
        </p>
      </nav>
      <div id='filecontents'>
        <h1 id="design-overview">Design overview</h1><p>The core of kermit is built around the representation of a request to a given URL - <a href="../../class/RequestItem.html">RequestItem</a> - 
and the implementation of a series of well-defined <strong>processing phases</strong> applied to each of those items. Items &quot;transition&quot; from one 
phase to the other, usually from phase <a href="../../class/INITIAL.html">INITIAL</a> to phase <a href="../../class/COMPLETE.html">COMPLETE</a>.</p><h2 id="processing-phases">Processing Phases</h2><p>Each processing phase contains a set of handlers that do some work on the request item they receive.
These handlers are provided by <a href="../../class/Extension.html">Extension</a>s and are inserted during initialization 
of the <a href="../../class/Crawler.html">Crawler</a>. 
The execution of a processing phase for a given item involves the invocation of all handlers (in order of insertion).</p><p>All items are held in a <a href="../../class/QueueManager.html">queueing backend</a> and the node.js event loop is used to to schedule processing callbacks for 
the items that are at the head of the queue.</p><p>All defined processing phases as well as their allowed transitions are illustrated in the diagram below.</p><pre><code class="lang-txt"> .-------------.
 |   INITIAL   |
 |-------------|
 | Unprocessed |
 |             |
 &#39;-------------&#39;   \
        |           \
        |            \
        |             v
        v             .--------------------.
 .-------------.      |  ERROR | CANCELED  |      .-----------.
 |  SPOOLED    |      |--------------------|      | COMPLETED |
 |-------------|  ---&gt;| - Error            |      |-----------|
 | Waiting for |      | - Duplicate        |      | Done!     |
 | free slot   |      | - Blacklisted etc. |      |           |
 &#39;-------------&#39;      &#39;--------------------&#39;      &#39;-----------&#39;
        |             ^         ^          ^            ^
        |            /          |           \           |
        |           /           |            \          |
        v          /                          \         |
 .-------------.         .-------------.          .-----------.
 |    READY    |         |  FETCHING   |          |  FETCHED  |
 |-------------|         |-------------|          |-----------|
 | Ready for   |--------&gt;| Response    |---------&gt;| Content   |
 | fetching    |         | streaming   |          | received  |
 &#39;-------------&#39;         &#39;-------------&#39;          &#39;-----------&#39;
</code></pre>
<h2 id="processing-extensions">Processing Extensions</h2><p><a href="../../class/Extension.html">Extension</a>s are reusable components designed to accomplish specific tasks like storing content 
on local file system or scanning content for certain words. Extensions can attach handlers to 
any of the processing phases. Most of Kermit&#39;s core functionality is implemented based on this extension
mechanism. Core extensions provide functionality for request filtering, rate limiting and throttling. 
List of core extensions:</p><ul>
<li><a href="../../class/ExtensionPointConnector.html">RequestFilter</a></li>
<li><a href="../../class/ExtensionPointConnector.html">ExtensionPointConnector</a></li>
<li><a href="../../class/RequestItemMapper.html">RequestItemMapper</a></li>
<li><a href="../../class/QueueConnector.html">QueueConnector</a></li>
<li><a href="../../class/QueueWorker.html">QueueWorker</a></li>
<li><a href="../../class/Spooler.html">RequestStreamer</a></li>
<li><a href="../../class/Spooler.html">Spooler</a></li>
<li><a href="../../class/Completer.html">Completer</a></li>
<li><a href="../../class/Cleanup.html">Cleanup</a></li>
</ul>
<h2 id="tutorial">Tutorial</h2><p>The following sections are meant to walk you through the most fundamental parts of the API from a user&#39;s
perspective.</p><h3 id="instantiation">Instantiation</h3><p>Instantiation of a Crawler is very simple as Kermit comes with a lot of default options.
An absolute minimal example looks like this:</p><pre><code class="lang-cs"># Require the main class from the modules package
{Crawler} = require &#39;../kermit/kermit.modules&#39;

# This will initialize a crawler with default options and no particularly interesting functionality
Kermit = new Crawler
  name: &quot;name your crawler here&quot; 
# This will issue a request and then detect that there is not much to do with the result (no writable streams attached)
# so the program will do nothing but be kept alive forever
Kermit.schedule(&quot;http://www.yourtargeturl.info&quot;)
</code></pre><p>A more elaborate and useful example could look like this:</p><pre><code class="lang-cs">
# Require the main class and extensions
{Crawler, ext} = require &#39;../kermit/kermit.modules&#39;
{ResourceDiscovery, Monitoring, OfflineStorage} = ext

# Configure a crawler with some useful extensions
Kermit = new Crawler
  name: &quot;downloader&quot;
  extensions : [
    new OfflineStorage # Add storage to local file system
    new Monitoring # Add regular computation of runtime statistics to log level INFO
    new ResourceDiscovery # Add discovery of href and other resources
  ]
# This will start the crawling process
# The resource discovery extension will scan all html files for links and schedule new requests for each
# NOTE: This program might never stop crawling so maybe you want to add some boundaries
Kermit.schedule(&quot;http://www.yourtargeturl.info&quot;)
</code></pre><p>An example that is likely to finish crawling after all allowed URLs have been visited looks like this:</p><pre><code class="lang-cs">
# Require the main class and extensions
{Crawler, ext} = require &#39;../kermit/kermit.modules.coffee&#39;
{ResourceDiscovery, Monitoring, OfflineStorage} = ext

# Configure a crawler with some useful extensions
Kermit = new Crawler
  name: &quot;download-apidocs&quot;
  extensions : [
    new OfflineStorage # Add storage to local file system
    new Monitoring # Add regular computation of runtime statistics to log level INFO
    new ResourceDiscovery # Add discovery of href and other resources
  ]
  Options:
    Filtering:
        allow : [
          /.*apidocs\.info.*/
        ]

# This will initiate the crawling process
# All discovered URLs outside of the domain &#39;apidocs.info&#39; will not be executed
# As long as URLs under apidocs.info do not contain autogenerated ids, crawling will
# eventually finish 
Kermit.schedule(&quot;http://www.apidocs.info&quot;)
</code></pre>
<h3 id="options">Options</h3><p>Most of the features provided by Kermit are implemented as extensions. Each of those extensions
offers some options to configure its behaviour. To pass options down to the core extensions use the
&#39;Options&#39; property of the configuration object.</p><pre><code class="lang-cs">
Kermit = new Crawler
  name: &quot;download-apidocs&quot;
  Options : 
    Filtering: ... # Options for request filtering go here
    Logging: ... # You can pass a log configuration of your choice
    Queuing: ... # Add rate limits and other features as provided by the queuing system
</code></pre>
<h3 id="log-configuration">Log configuration</h3><p>The <a href="../../class/LogHub.html">LogHub</a> is initialized with a log configuration that tells it what appenders
and log formats to use.</p><pre><code class="lang-cs">
Kermit = new Crawler
  name: &quot;download-apidocs&quot;
  Options : 
    Logging:
      levels : [&#39;trace&#39;, &#39;info&#39;, &#39;error&#39;, &#39;warn&#39;]
      destinations: [
        {
          appender:
            type : &#39;console&#39;
          levels : [&#39;trace&#39;, &#39;error&#39;, &#39;info&#39;, &#39;warn&#39;]
        },
        {
        appender :
              type : &#39;file&#39;
              filename : &quot;/tmp/crawler/logs/full.log&quot;
            levels: [&#39;trace&#39;, &#39;error&#39;, &#39;info&#39;, &#39;debug&#39;, &#39;warn&#39;]
        }    
      ]
</code></pre><p>There are a number of <a href="../../file/src/kermit/Logging.conf.coffee.html">predefined log configurations</a> that can be used.
It is also easily possible to roll up a custom configuration following the code examples from that file.</p><h3 id="scheduling-of-urls">Scheduling of URLs</h3><p>To reduce the memory footprint, not every URL submission will create a request item immediately (as request items are
persistent, ie. increase queue size and affect query performance).
Therefore, a <a href="../../class/Scheduler.html">Scheduler</a> is used to keep track of submitted URLs and 
schedule a request when the load limits allow.</p><h2 id="feature-extensions">Feature extensions</h2>
<ul>
<li><a href="../../class/ResourceDiscovery.html">ResourceDiscovery</a></li>
<li><a href="../../class/Monitoring.html">Monitoring</a></li>
<li><a href="../../class/OfflineStorage.html">OfflineStorage</a></li>
<li><a href="../../class/OfflineServer.html">OfflineServer</a></li>
</ul>
<h2 id="custom-extensions">Custom Extensions</h2><p>This will become a guide for implementing your own extensions. Until then, please have a look
at the code of the various available extensions. It&#39;s fairly easy to get started.</p>
      </div>
    </div>
    <div id='footer'>
  February 08, 16 13:25:27 by
  <a href='https://github.com/coffeedoc/codo' title='CoffeeScript API documentation generator'>
    Codo
  </a>
  2.0.10
  &#10034;
  Press H to see the keyboard shortcuts
  &#10034;
  <a href='http://twitter.com/netzpirat' target='_parent'>@netzpirat</a>
  &#10034;
  <a href='http://twitter.com/_inossidabile' target='_parent'>@_inossidabile</a>
</div>
<iframe id='search_frame'></iframe>
<div id='fuzzySearch'>
  <input type='text'>
  <ol></ol>
</div>
<div id='help'>
  <p>
    Quickly fuzzy find classes, mixins, methods, file:
  </p>
  <ul>
    <li>
      <span>T</span>
      Open fuzzy finder dialog
    </li>
  </ul>
  <p>
    Control the navigation frame:
  </p>
  <ul>
    <li>
      <span>L</span>
      Toggle list view
    </li>
    <li>
      <span>C</span>
      Show class list
    </li>
    <li>
      <span>I</span>
      Show mixin list
    </li>
    <li>
      <span>F</span>
      Show file list
    </li>
    <li>
      <span>M</span>
      Show method list
    </li>
    <li>
      <span>E</span>
      Show extras list
    </li>
  </ul>
  <p>
    You can focus and blur the search input:
  </p>
  <ul>
    <li>
      <span>S</span>
      Focus search input
    </li>
    <li>
      <span>Esc</span>
      Blur search input
    </li>
  </ul>
</div>
  </body>
</html>